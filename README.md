# ğŸ· Wine Quality Prediction

![Wine Pouring GIF](https://media.tenor.com/PLIr_VkF6ywAAAAM/ghostedvpn-hacker-cat.gif)

Predicting wine quality based on physicochemical properties like **acidity, sugar, sulphates, and alcohol** using Machine Learning models.  

---

## ğŸ“Š Dataset Overview

| Feature             | Type       | Description                              |
|--------------------|-----------|------------------------------------------|
| Records            | 1,143     | Wine samples                              |
| Columns            | 13        | 11 float + 2 integer                      |
| Target Variable    | `quality` | Wine quality score (3â€“8)                 |
| Missing Values     | 0         | Clean dataset                             |

**Target Column Details:**  
- `quality` â†’ integer values ranging from **3 to 8**, representing wine quality ratings.  
- Class distribution is imbalanced, mostly **5 and 6**.  

---

## ğŸ§¹ Data Preprocessing & EDA

- Checked data structure using `.info()` and `.describe()`.  
- Verified **class imbalance** using `train['quality'].value_counts()`.  
- **Visualizations:**  
  - Pairplots, boxplots, scatterplots, and correlation heatmap to explore relationships.  
  - Example pairplot (replace with your image path):
  

---

## âš™ï¸ Feature Preparation

- **Feature-Target Split:**  
  - `X` â†’ all chemical attributes (features)  
  - `y` â†’ quality (target)  
- **Train-Test Split:** 80% / 20% (`random_state=42`)  
- **Scaling:** StandardScaler applied to normalize features  

---

## âš–ï¸ Handling Class Imbalance

- **SMOTE:** Oversampled minority classes  
- **RandomUnderSampler:** Balanced majority classes  
- Verified using `y_resampled.value_counts(normalize=True)` âœ…  

---

## ğŸ§  Modeling Stage

| Model                 | Accuracy | Badge |
|----------------------|---------|-------|
| Logistic Regression   | 88.60%  | ![LR](https://img.shields.io/badge/Logistic%20Regression-88.6%25-brightgreen) |
| Support Vector        | 88.17%  | ![SVC](https://img.shields.io/badge/SVC-88.2%25-green) |
| GaussianNB            | 77.20%  | ![Gaussian](https://img.shields.io/badge/GaussianNB-77.2%25-yellow) |
| Decision Tree         | 57.63%  | ![DT](https://img.shields.io/badge/Decision%20Tree-57.6%25-orange) |
| Random Forest         | 88.00%  | ![RF](https://img.shields.io/badge/Random%20Forest-88%25-brightgreen) |

**ğŸ’¡ Top Models:** Logistic Regression, SVC, Random Forest  

---

## ğŸ”‘ Key Insights

![Wine Insight GIF](https://media.giphy.com/media/3o7abKhOpu0NwenH3O/giphy.gif)

- Higher **alcohol** â†’ higher wine quality ğŸ·  
- Higher **volatile acidity** â†’ lower quality âš ï¸  
- Alcohol is **strongest positive predictor**, volatile acidity is **strongest negative predictor**  

---

## ğŸš€ Conclusion

- Dataset cleaned, scaled, and balanced âœ…  
- Visualizations revealed **key factors** affecting wine quality ğŸ“Š  
- Logistic Regression, SVC, and Random Forest achieved **~88% accuracy** ğŸ’¯  
- Dataset and models are **ready for deployment or further experimentation** ğŸ’»  

---

## ğŸ› ï¸ Tech Stack

- Python 3  
- Pandas, NumPy  
- Scikit-learn  
- Seaborn, Matplotlib  
- Imbalanced-learn (SMOTE & UnderSampling)  

---

> Made with â¤ï¸ by **[Humna Ghouri]**

